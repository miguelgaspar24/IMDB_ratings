{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avatar: The Last Airbender\n",
      "Processing series 1 of 24: Avatar: The Last Airbender\n",
      "The Legend of Korra\n",
      "Processing series 2 of 24: The Legend of Korra\n",
      "Gravity Falls\n",
      "Processing series 3 of 24: Gravity Falls\n",
      "The Owl House\n",
      "Processing series 4 of 24: The Owl House\n",
      "Amphibia\n",
      "Processing series 5 of 24: Amphibia\n",
      "Star vs. the Forces of Evil\n",
      "Processing series 6 of 24: Star vs. the Forces of Evil\n",
      "Steven Universe\n",
      "Processing series 7 of 24: Steven Universe\n",
      "Steven Universe Future\n",
      "Processing series 8 of 24: Steven Universe Future\n",
      "Bee and PuppyCat\n",
      "Processing series 9 of 24: Bee and PuppyCat\n",
      "She-Ra and the Princesses of Power\n",
      "Processing series 10 of 24: She-Ra and the Princesses of Power\n",
      "Kipo and the Age of Wonderbeasts\n",
      "Processing series 11 of 24: Kipo and the Age of Wonderbeasts\n",
      "\n",
      "Ecountered the following issue for Number of Seasons: 'NoneType' object has no attribute 'text' \n",
      "\n",
      "Over the Garden Wall\n",
      "Processing series 12 of 24: Over the Garden Wall\n",
      "Arcane: League of Legends\n",
      "Processing series 13 of 24: Arcane: League of Legends\n",
      "\n",
      "Ecountered the following issue in Arcane: League of Legends for Show Creators: list index out of range \n",
      "\n",
      "\n",
      "Ecountered the following issue in Arcane: League of Legends for season 2 data: All arrays must be of the same length \n",
      "\n",
      "Cike Wu Liuqi\n",
      "Processing series 14 of 24: Cike Wu Liuqi\n",
      "BoJack Horseman\n",
      "Processing series 15 of 24: BoJack Horseman\n",
      "Kid Cosmic\n",
      "Processing series 16 of 24: Kid Cosmic\n",
      "\n",
      "Ecountered the following issue for Number of Seasons: 'NoneType' object has no attribute 'text' \n",
      "\n",
      "Oni: Kamigami Yama no Onari\n",
      "Processing series 17 of 24: Oni: Kamigami Yama no Onari\n",
      "\n",
      "Ecountered the following issue in Oni: Kamigami Yama no Onari for Show Creators: list index out of range \n",
      "\n",
      "The Dragon Prince\n",
      "Processing series 18 of 24: The Dragon Prince\n",
      "Gargoyles\n",
      "Processing series 19 of 24: Gargoyles\n",
      "\n",
      "Ecountered an issue in Gargoyles for S2.E42 Air Date: Feb 1996 \n",
      "\n",
      "Samurai Jack\n",
      "Processing series 20 of 24: Samurai Jack\n",
      "The Amazing World of Gumball\n",
      "Processing series 21 of 24: The Amazing World of Gumball\n",
      "\n",
      "Ecountered an issue in The Amazing World of Gumball for S1.E21 Air Date: Sep 2011 \n",
      "\n",
      "\n",
      "Ecountered an issue in The Amazing World of Gumball for S2.E29 Air Date: Aug 2013 \n",
      "\n",
      "\n",
      "Ecountered an issue in The Amazing World of Gumball for S2.E37 Air Date: Nov 2013 \n",
      "\n",
      "\n",
      "Ecountered the following issue in The Amazing World of Gumball for season 7 data: All arrays must be of the same length \n",
      "\n",
      "Regular Show\n",
      "Processing series 22 of 24: Regular Show\n",
      "Count Duckula\n",
      "Processing series 23 of 24: Count Duckula\n",
      "\n",
      "Ecountered the following issue in Count Duckula for Show Creators: list index out of range \n",
      "\n",
      "\n",
      "Ecountered the following issue in Count Duckula for season 2 data: All arrays must be of the same length \n",
      "\n",
      "Love, Death & Robots\n",
      "Processing series 24 of 24: Love, Death & Robots\n",
      "\n",
      "Ecountered the following issue in Love, Death & Robots for season 4 data: All arrays must be of the same length \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Show Title</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode Number</th>\n",
       "      <th>Episode Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Votes</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avatar: The Last Airbender</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The Boy in the Iceberg</td>\n",
       "      <td>7.9</td>\n",
       "      <td>5800.0</td>\n",
       "      <td>21/02/2005</td>\n",
       "      <td>The legend of the Avatar is told. Katara and S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avatar: The Last Airbender</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The Avatar Returns</td>\n",
       "      <td>8.1</td>\n",
       "      <td>5200.0</td>\n",
       "      <td>21/02/2005</td>\n",
       "      <td>Aang and Katara inadvertently set off a trap t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Avatar: The Last Airbender</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>The Southern Air Temple</td>\n",
       "      <td>8.4</td>\n",
       "      <td>5100.0</td>\n",
       "      <td>25/02/2005</td>\n",
       "      <td>After his departure from the Southern Air Temp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avatar: The Last Airbender</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The Warriors of Kyoshi</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4900.0</td>\n",
       "      <td>04/03/2005</td>\n",
       "      <td>The gang arrives at Kyoshi Island and are capt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Avatar: The Last Airbender</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The King of Omashu</td>\n",
       "      <td>8.1</td>\n",
       "      <td>4900.0</td>\n",
       "      <td>18/03/2005</td>\n",
       "      <td>Aang's abilities as an airbender are challenge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Love, Death &amp; Robots</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Kill Team Kill</td>\n",
       "      <td>6.4</td>\n",
       "      <td>9700.0</td>\n",
       "      <td>20/05/2022</td>\n",
       "      <td>US Special Forces are trained to neutralize an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Love, Death &amp; Robots</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Swarm</td>\n",
       "      <td>6.9</td>\n",
       "      <td>9500.0</td>\n",
       "      <td>20/05/2022</td>\n",
       "      <td>Two human scientists study the secrets of an a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Love, Death &amp; Robots</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Mason's Rats</td>\n",
       "      <td>7.6</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>20/05/2022</td>\n",
       "      <td>Welcome to the Ratpocalypse! Farmer Mason know...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Love, Death &amp; Robots</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>In Vaulted Halls Entombed</td>\n",
       "      <td>7.2</td>\n",
       "      <td>9300.0</td>\n",
       "      <td>20/05/2022</td>\n",
       "      <td>Deep in the mountains of Afghanistan, a squad ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Love, Death &amp; Robots</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Jibaro</td>\n",
       "      <td>8.1</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>20/05/2022</td>\n",
       "      <td>A deaf knight and a siren of myth become entwi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1492 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Original Show Title  Season  Episode Number  \\\n",
       "0   Avatar: The Last Airbender       1             1.0   \n",
       "1   Avatar: The Last Airbender       1             2.0   \n",
       "2   Avatar: The Last Airbender       1             3.0   \n",
       "3   Avatar: The Last Airbender       1             4.0   \n",
       "4   Avatar: The Last Airbender       1             5.0   \n",
       "..                         ...     ...             ...   \n",
       "4         Love, Death & Robots       3             5.0   \n",
       "5         Love, Death & Robots       3             6.0   \n",
       "6         Love, Death & Robots       3             7.0   \n",
       "7         Love, Death & Robots       3             8.0   \n",
       "8         Love, Death & Robots       3             9.0   \n",
       "\n",
       "                Episode Title  Rating    Votes    Air Date  \\\n",
       "0      The Boy in the Iceberg     7.9   5800.0  21/02/2005   \n",
       "1          The Avatar Returns     8.1   5200.0  21/02/2005   \n",
       "2     The Southern Air Temple     8.4   5100.0  25/02/2005   \n",
       "3      The Warriors of Kyoshi     8.0   4900.0  04/03/2005   \n",
       "4          The King of Omashu     8.1   4900.0  18/03/2005   \n",
       "..                        ...     ...      ...         ...   \n",
       "4              Kill Team Kill     6.4   9700.0  20/05/2022   \n",
       "5                       Swarm     6.9   9500.0  20/05/2022   \n",
       "6                Mason's Rats     7.6  10000.0  20/05/2022   \n",
       "7   In Vaulted Halls Entombed     7.2   9300.0  20/05/2022   \n",
       "8                      Jibaro     8.1  15000.0  20/05/2022   \n",
       "\n",
       "                                          Description  \n",
       "0   The legend of the Avatar is told. Katara and S...  \n",
       "1   Aang and Katara inadvertently set off a trap t...  \n",
       "2   After his departure from the Southern Air Temp...  \n",
       "3   The gang arrives at Kyoshi Island and are capt...  \n",
       "4   Aang's abilities as an airbender are challenge...  \n",
       "..                                                ...  \n",
       "4   US Special Forces are trained to neutralize an...  \n",
       "5   Two human scientists study the secrets of an a...  \n",
       "6   Welcome to the Ratpocalypse! Farmer Mason know...  \n",
       "7   Deep in the mountains of Afghanistan, a squad ...  \n",
       "8   A deaf knight and a siren of myth become entwi...  \n",
       "\n",
       "[1492 rows x 8 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set target URL\n",
    "base_url = 'https://www.imdb.com/title/'\n",
    "url_list = [\n",
    "            'tt0417299',   # Avatar: The Last Airbender\n",
    "            'tt1695360',   # The Legend Of Korra\n",
    "            'tt1865718',   # Gravity Falls\n",
    "            'tt8050756',   # The Owl House\n",
    "            'tt8050740',   # Amphibia\n",
    "            'tt2758770',   # Star Vs. The Forces Of Evil\n",
    "            'tt3061046',   # Steven Universe\n",
    "            'tt13714610',  # Steven Universe Future\n",
    "            'tt4163486',   # Bee and PuppyCat\n",
    "            'tt7745956',   # She-Ra And The Princesses Of Power\n",
    "            'tt10482560',  # Kipo And The Age Of Wonderbeasts\n",
    "            'tt3718778',   # Over The Garden Wall\n",
    "            'tt11126994',  # Arcane: League of Legends\n",
    "            'tt10384610',  # Scissor Seven\n",
    "            'tt3398228',   # Bojack Horseman\n",
    "            'tt9248538',   # Kid Cosmic\n",
    "            'tt9894516',   # Oni: Thunder God's Tale\n",
    "            'tt8688814',   # The Dragon Prince\n",
    "            'tt0108783',   # Gargoyles\n",
    "            'tt0278238',   # Samurai Jack\n",
    "            'tt1942683',   # The Amazing World of Gumball\n",
    "            'tt1710308',   # Regular Show\n",
    "            'tt0088500',   # Count Duckula\n",
    "            'tt9561862'   # Love, Death & Robots\n",
    "            ]\n",
    "\n",
    "global_aux_df = pd.DataFrame()\n",
    "global_reviews_df = pd.DataFrame()\n",
    "global_main_df = pd.DataFrame()\n",
    "\n",
    "for url_index, url in enumerate(url_list):\n",
    "\n",
    "    # Get main page HTML information\n",
    "    main_page = requests.get(base_url + url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    main_soup = BeautifulSoup(main_page.content, 'html.parser')\n",
    "\n",
    "    # Number of Episodes\n",
    "    n_episodes = main_soup.find_all('span', class_='ipc-title__subtext')[0].text\n",
    "\n",
    "    # Number of Seasons\n",
    "    seasons_html = main_soup.find('label', class_='ipc-simple-select__label')\n",
    "\n",
    "    # Fix issue with Over the Garden Wall number of seasons\n",
    "    try:\n",
    "        n_seasons = int(seasons_html.text.split(' ')[0])\n",
    "    except AttributeError as attribute_error:\n",
    "        print('\\nEncountered the following issue for Number of Seasons:', attribute_error, '\\n')\n",
    "        data_json = main_soup.find_all('script', id=\"__NEXT_DATA__\")[0]\n",
    "        data_attributes = json.loads(data_json.text)['props']['pageProps']\n",
    "        n_seasons = data_attributes['mainColumnData']['episodes']['seasons'][0]['number'] \n",
    "\n",
    "    # List each season's URL\n",
    "    seasons_urls = [base_url + url + '/episodes?season={}'.format(n+1) for n in range(n_seasons)]\n",
    "\n",
    "##########################################################################################################\n",
    "##########################################################################################################\n",
    "\n",
    "####                                 AUXILIARY DATA\n",
    "\n",
    "##########################################################################################################\n",
    "##########################################################################################################\n",
    "\n",
    "    auxiliary_data = {}\n",
    "\n",
    "    # Get JSON data embedded in main page HTML containing general show information\n",
    "    data_json = main_soup.find_all('script', id=\"__NEXT_DATA__\")[0]\n",
    "    data_attributes = json.loads(data_json.text)['props']['pageProps']['aboveTheFoldData']\n",
    "\n",
    "    # Original Title\n",
    "    original_title = data_attributes['originalTitleText']['text']\n",
    "    print(original_title)\n",
    "    auxiliary_data['Original Show Title'] = original_title\n",
    "\n",
    "    print('Processing series', str(url_index + 1), 'of', str(len(url_list)) + ':', original_title)\n",
    "\n",
    "    # Overall Rating\n",
    "    overall_rating = data_attributes['ratingsSummary']['aggregateRating']\n",
    "    auxiliary_data['Overall Rating'] = overall_rating\n",
    "\n",
    "    # Overall Votes\n",
    "    overall_votes = data_attributes['ratingsSummary']['voteCount']\n",
    "    auxiliary_data['Total Votes'] = overall_votes\n",
    "\n",
    "    # Episode Runtime\n",
    "    runtime = str(int(data_attributes['runtime']['seconds'] / 60)) + 'min.'\n",
    "    auxiliary_data['Runtime'] = runtime\n",
    "\n",
    "    # Series Genres\n",
    "    genres = [item['text'] for item in data_attributes['genres']['genres']]\n",
    "    auxiliary_data['Genres'] = [genres]\n",
    "\n",
    "    # Country of Origin\n",
    "    country_of_origin = data_attributes['countriesOfOrigin']['countries'][0]['id']\n",
    "    auxiliary_data['Country of Origin'] = country_of_origin\n",
    "\n",
    "    # Air Dates (Years)\n",
    "    start_year = data_attributes['releaseYear']['year']\n",
    "    end_year = data_attributes['releaseYear']['endYear']\n",
    "    auxiliary_data['Start Year'] = start_year\n",
    "    auxiliary_data['End Year'] = end_year\n",
    "\n",
    "    # Poster Image\n",
    "    poster_image = data_attributes['primaryImage']['url']\n",
    "    auxiliary_data['Poster Image'] = poster_image\n",
    "\n",
    "    # Credits (Creators//Production Company/Writers)\n",
    "    # Fix issue with Arcane missing show creators\n",
    "    try:\n",
    "        show_creators = [credit['name']['nameText']['text'] for credit in data_attributes['creatorsPageTitle'][0]['credits']]\n",
    "    except IndexError as index_error:\n",
    "        print('\\nEncountered the following issue in', original_title, 'for Show Creators:', index_error, '\\n')\n",
    "        show_creators = ['Not Found']\n",
    "\n",
    "    production_company = data_attributes['production']['edges'][0]['node']['company']['companyText']['text']\n",
    "    auxiliary_data['Show Creators'] = [show_creators]\n",
    "    auxiliary_data['Production Company'] = production_company\n",
    "\n",
    "    # Total Amount of Reviews\n",
    "    n_reviews = data_attributes['reviews']['total']\n",
    "    auxiliary_data['Total Reviews'] = n_reviews\n",
    "\n",
    "    # Plot\n",
    "    plot_text = data_attributes['plot']['plotText']['plainText']\n",
    "    auxiliary_data['Plot'] = plot_text\n",
    "\n",
    "    # Save current series data\n",
    "    auxiliary_df = pd.DataFrame.from_dict(auxiliary_data)\n",
    "\n",
    "    # Save data to global DataFrame\n",
    "    global_aux_df = pd.concat([global_aux_df, auxiliary_df], axis=0)\n",
    "\n",
    "##########################################################################################################\n",
    "##########################################################################################################\n",
    "\n",
    "####                                 REVIEWS DATA\n",
    "\n",
    "##########################################################################################################\n",
    "##########################################################################################################\n",
    "\n",
    "    start_url = base_url + url + '/reviews'\n",
    "    link = base_url + url + '/reviews/_ajax'\n",
    "\n",
    "    params = {\n",
    "            'ref_': 'undefined',\n",
    "            'paginationKey': ''\n",
    "            }\n",
    "\n",
    "    reviews = {\n",
    "            'Original Show Title': [],\n",
    "            'Review Title': [],\n",
    "            'Review Content': [],\n",
    "            'Review Date': []\n",
    "            }\n",
    "\n",
    "    with requests.Session() as session:\n",
    "        result = session.get(start_url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "\n",
    "        while True:\n",
    "\n",
    "            # Get reviews page HTML information\n",
    "            soup = BeautifulSoup(result.text,'html.parser')\n",
    "            for item in soup.select('.review-container'):\n",
    "\n",
    "                # Review Title, Date, and Content\n",
    "                review_title = item.find_all('a', class_='title')[0].text.strip()\n",
    "                review_content = item.find_all('div', class_='text show-more__control')[0].text.strip().replace(\"n\\\\'t\", \"n't\")\n",
    "                review_date = item.find_all('span', class_='review-date')[0].text\n",
    "\n",
    "                # Save data\n",
    "                reviews['Original Show Title'].append(original_title)\n",
    "                reviews['Review Title'].append(review_title)\n",
    "                reviews['Review Content'].append(review_content)\n",
    "                reviews['Review Date'].append(review_date)\n",
    "\n",
    "            # Load more reviews into the page\n",
    "            try:\n",
    "                pagination_key = soup.select_one('.load-more-data[data-key]').get('data-key')\n",
    "            except AttributeError:\n",
    "                break\n",
    "            params['paginationKey'] = pagination_key\n",
    "            result = session.get(link, params=params)\n",
    "\n",
    "    # Save current series data\n",
    "    reviews_df = pd.DataFrame(data=reviews)\n",
    "\n",
    "    # Save data to global DataFrame\n",
    "    global_reviews_df = pd.concat([global_reviews_df, reviews_df], axis=0)\n",
    "\n",
    "##########################################################################################################\n",
    "##########################################################################################################\n",
    "\n",
    "####                                 MAIN DATA\n",
    "\n",
    "##########################################################################################################\n",
    "##########################################################################################################\n",
    "\n",
    "    full_dataset_df = pd.DataFrame()\n",
    " \n",
    "    for season in seasons_urls:\n",
    "\n",
    "        # Season Number\n",
    "        season_num = int(season[-1])\n",
    "\n",
    "        # Get current season page HTML information\n",
    "        season_page = requests.get(season, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        season_soup = BeautifulSoup(season_page.content, 'html.parser')\n",
    "\n",
    "        # Episode Title\n",
    "        episode_title_html = season_soup.find_all('a', href=lambda x: '?ref_=ttep_ep' in x)\n",
    "        episodes_title = [block.text.split(' âˆ™ ')[1] for b, block in enumerate(episode_title_html) if b % 2 != 0]\n",
    "\n",
    "        # Episode Number\n",
    "        episodes_number = [int(block.text.split(' âˆ™ ')[0][4:]) for b, block in enumerate(episode_title_html) if b % 2 != 0]\n",
    "\n",
    "        # Episode Rating\n",
    "        episode_rating_html = season_soup.find_all('span', class_='ipc-rating-star ipc-rating-star--base ipc-rating-star--imdb ratingGroup--imdb-rating')\n",
    "        episodes_rating = [round(float(block.text[:3]), 1) for block in episode_rating_html]\n",
    "\n",
    "        # Episode Votes\n",
    "        episodes_votes = [int(block.text.split('(')[1][:-2].replace('.', '') + '00') if '.' in block.text.split('(')[1] \\\n",
    "                            else int(block.text.split('(')[1][:-2] + '000') for block in episode_rating_html]\n",
    "\n",
    "        # Episode Air Date\n",
    "        episode_airdate_html = season_soup.find_all('span', class_='sc-9115db22-10 jAfkDE')\n",
    "\n",
    "        # Fix issue with Gargoyles and The Amazing World of Gumball air dates\n",
    "        episodes_airdate_text = []\n",
    "        for b, block in enumerate(episode_airdate_html):\n",
    "            if len(block.text) < 16:\n",
    "                print('\\nEcountered an issue in', original_title, 'for S' + str(season_num) + '.E' + str(episodes_number[b]), 'Air Date:', block.text, '\\n')\n",
    "                month = block.text.split(' ')[0]\n",
    "                day = str(int(episodes_airdate_text[b - 1][3:6].strip()) + 1)\n",
    "                year = block.text.split(' ')[1]\n",
    "                reconstructed_date = ' '.join([month, day, year])\n",
    "                episodes_airdate_text.append(reconstructed_date)\n",
    "            else:\n",
    "                episodes_airdate_text.append(block.text[5:].replace(',', ''))\n",
    "        episodes_airdate_date = [datetime.strptime(text, '%b %d %Y').strftime('%d/%m/%Y') for text in episodes_airdate_text]\n",
    "\n",
    "        # Episode Description\n",
    "        episode_description_html = season_soup.find_all('div', class_='ipc-html-content-inner-div')\n",
    "        episodes_description = [block.text for block in episode_description_html]\n",
    "\n",
    "        # Remove \"Episode 0\" from season 1 of ATLA\n",
    "        if original_title == 'Avatar: The Last Airbender' and season_num == 1:\n",
    "            episodes_number = episodes_number[1:]\n",
    "            episodes_title = episodes_title[1:]\n",
    "            episodes_rating = episodes_rating[1:]\n",
    "            episodes_votes = episodes_votes[1:]\n",
    "            episodes_airdate_date = episodes_airdate_date[1:]\n",
    "            episodes_description = episodes_description[1:]\n",
    "        \n",
    "        # Save current series data\n",
    "        data = {\n",
    "                'Original Show Title': original_title,\n",
    "                'Season': season_num,\n",
    "                'Episode Number': episodes_number,\n",
    "                'Episode Title': episodes_title,\n",
    "                'Rating': episodes_rating,\n",
    "                'Votes': episodes_votes,\n",
    "                'Air Date': episodes_airdate_date,\n",
    "                'Description': episodes_description\n",
    "                }\n",
    "\n",
    "        # Fix issue with unaired season with unavailable data for The Amazing World of Gumball season 7 and Arcane season 2\n",
    "        try:\n",
    "            season_df = pd.DataFrame.from_dict(data)\n",
    "        except ValueError as value_error:\n",
    "            print('\\nEncountered the following issue in', original_title, 'for season', str(season_num), 'data:', value_error, '\\n')\n",
    "            break\n",
    "\n",
    "        full_dataset_df = pd.concat([full_dataset_df, season_df])\n",
    "\n",
    "    # Save data to global DataFrame\n",
    "    global_main_df = pd.concat([global_main_df, full_dataset_df], axis=0)\n",
    "\n",
    "# Export all saved data to Excel spreadsheets\n",
    "global_aux_df.to_excel('aux_data.xlsx', header=True, index=False)\n",
    "global_reviews_df.to_excel('reviews_data.xlsx', header=True, index=False)\n",
    "global_main_df.to_excel('main_data.xlsx', header=True, index=False)\n",
    "\n",
    "global_main_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imdb_ratings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "144e399d4a17dd6a81069e75c8392f41e0e18b404b6b384016800e05192d90b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
